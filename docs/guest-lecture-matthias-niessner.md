---
hide:
  - navigation
  - toc
---

# Guest Lecture 3: Photo-Realistic AI Avatars
## [Matthias Nießner](https://www.niessnerlab.org/){:target="_blank"}
### Professor at Technical University of Munich<br>May 20, 2025 (Tue), 4:00 p.m. KST<br>Online (Zoom).

### <b>Guest Lecture at [CS479: Machine Learning for 3D Data](../){:target="_blank"}<br>[Minhyuk Sung](http://mhsung.github.io/){:target="_blank"}, [KAIST](https://www.kaist.ac.kr/){:target="_blank"}, Spring 2025</b>

<br />
![Teaser](assets/guest-lecture-matthias-niessner.png){ width=90% style="display: block; margin: 0 auto" }[^1]

[^1]: Image from NPGA: Neural Parametric Gaussian Avatars(https://arxiv.org/abs/2405.19331).  

### **Abstract**
In this lecture, I will talk about our latest research on creating photo-realistic AI Avatars. Here, the main goal is to create virtual characters that can are visually indistinguishable from photos and videos of real people. Further, we aim to control such avatars with multi-modal control signals such as animation rigs, text, or voice in order to replicate real-world conversations and leverage our avatars for 3D content creation. Ultimately, the goal is to witness the evolution of photos and videos into interactive, holographic 3D content that is indistinguishable from the physical reality. To this end, we focus on the possibility of capturing and sharing 3D photos with friends, family, or through social media platforms. Imagine the ability to comprehensively document historical events along with the participating people for future generations, or to generate content for upcoming applications in augmented and virtual reality.

### **Bio**
Matthias Nießner is a Professor at the Technical University of Munich, where he leads the Visual Computing Lab. Before, he was a Visiting Assistant Professor at Stanford University. Prof. Nießner’s research lies at the intersection of computer vision, graphics, and machine learning, where he is particularly interested in cutting-edge techniques for 3D reconstruction, semantic 3D scene understanding, video editing, and AI-driven video synthesis. In total, he has published over 150 academic publications, including 25 papers at the prestigious ACM Transactions on Graphics (SIGGRAPH / SIGGRAPH Asia) journal and 55 works at the leading vision conferences (CVPR, ECCV, ICCV); several of these works won best paper awards, including at SIGCHI’14, HPG’15, SPG’18, and the SIGGRAPH’16 Emerging Technologies Award for the best Live Demo. Prof. Nießner’s work enjoys wide media coverage, with many articles featured in main-stream media including the New York Times, Wall Street Journal, Spiegel, MIT Technological Review, and many more, and his was work led to several TV appearances such as on Jimmy Kimmel Live, where Prof. Nießner demonstrated the popular Face2Face technique; Prof. Nießner’s academic Youtube channel currently has over 5 million views. For his work, Prof. Nießner received several awards: he is a TUM-IAS Rudolph Moessbauer Fellow (2017 – ongoing), he won the Google Faculty Award for Machine Perception (2017), the Nvidia Professor Partnership Award (2018), as well as the prestigious ERC Starting Grant 2018 which comes with 1.5 million Euro in research funding; in 2019, he received the Eurographics Young Researcher Award honoring the best upcoming graphics researcher in Europe. In addition to his academic impact, Prof. Nießner is a co-founder and director of Synthesia Inc., a startup dedicated to democratize synthetic media generation with cutting-edge AI-driven video synthesis technology that recently reached unicorn status at 2.1B$ USD evaluation.
<br />

